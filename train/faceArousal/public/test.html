<!DOCTYPE html>
<html>
<head>
  <script src="tmp/face-api.js"></script>
  <script src="FileSaver.js"></script>
  <script src="commons.js"></script>
  <script src="js/faceExpressionsCommons.js"></script>
  <script src="js/test.js"></script>
</head>
<body>
  <div id="container"></div>

  <script>
    tf = faceapi.tf

    window.numDataPerClass = Infinity
    window.iterDelay = 0
    window.withLogging = true

    // load the FaceLandmark68Net and use it's feature extractor since we only
    // train the output layer of the FaceExpressionNet
    window.net = new faceapi.FaceArousalNet()

    // uri to weights file of last checkpoint
    window.modelCheckpoint = 'tmp/even-split/face_expression_model_2.weights'

    async function load() {
      window.testData = await faceapi.fetchJson('tmp/testData.json')

      // fetch the actual output layer weights
      const weights = await faceapi.fetchNetWeights(window.modelCheckpoint)
      await window.net.load(weights)

      console.log('loaded')
    }

    async function test() {
      await load()
      let window.lossValues = 0
      const createBatches = window.createBatches || function(data, batchSize) {
        const testInputs = prepareDataForTest(data)
        const batches = []
        for (let dataIdx = 0; dataIdx < testInputs.length; dataIdx += batchSize) {
          batches.push(testInputs.slice(dataIdx, dataIdx + batchSize))
        }
        return batches
      }

      const batches = createBatches(window.testData, window.batchSize)
      console.log(batches)
      for (const [batchIdx, batchData] of batches.entries()) {
        const tsIter = Date.now()

        let bImages = await Promise.all(
          batchData
            .map(data => faceapi.fetchImage(getImageUri(data)))
        )

        let tsBackward = Date.now()

        const netInput = await faceapi.toNetInput(bImages)
        const loss = computeLoss(netInput, batchData)

        tsBackward = Date.now() - tsBackward

        // start next iteration without waiting for loss data

        loss.data().then(data => {
          const lossValue = data[0]
          window.lossValues += lossValue
          window.withLogging && log(`epoch ${epoch}, batchIdx ${batchIdx} - loss: ${lossValue}, ( ${window.lossValues})`)
          loss.dispose()
          window.displayProgress && window.displayProgress(epoch, batchIdx, batches.length, window.lossValues)
        })

        window.withLogging && log(`epoch ${epoch}, batchIdx ${batchIdx} - backprop: ${tsBackward} ms, iter: ${Date.now() - tsIter} ms`)

        if (window.iterDelay) {
          await delay(window.iterDelay)
        } else {
          await tf.nextFrame()
        }
      }
  }
    // no optimizer in test script
    function computeLoss(netInput, batchData) {
      const bLabels = batchData
        .map(data => data.label)
      const labels = tf.tensor1d(bLabels).reshape([-1, 1])
      const out = window.net.runNet(netInput)
      /*change the loss*/
      const loss = tf.losses.meanSquaredError(
        labels,
        out,
        tf.Reduction.MEAN
      )
      return loss

    }

    function prepareDataForTest(data) {
      return  Object.keys(data).map(label => {
          const dataForLabel = data[label]//.map(data => ({ ...data, label }))
          let dataForLabelOut = dataForLabel

          return dataForLabelOut
        }).reduce((flat, arr) => arr.concat(flat))
      
    }

  </script>

</body>
</html>

